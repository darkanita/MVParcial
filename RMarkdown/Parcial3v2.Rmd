---
title: "Trabajo Multivariado"
subtitle: "Parcial 3"
author: "Ana María López - Pedro Pablo Villegas - Esteban Tabares"
date: "Noviembre, 2017"
citation_package: natbib
bibliography: Parcial3.bib
biblio-style: apalike
output: pdf_document
keep_md: true
editor_options: 
  chunk_output_type: console
---

```{r load myData, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Estructura de Directorios
dir.principal  <- "/Users/pedropablo/OneDrive/R/Analisis Multivariado/Parcial 3"
dir.funciones  <- "/Users/pedropablo/OneDrive/R/Analisis Multivariado/Parcial 3/RScripts"
dir.markdown  <- "/Users/pedropablo/OneDrive/R/Analisis Multivariado/Parcial 3/RMarkdown"
dir.input      <- "/Users/pedropablo/OneDrive/R/Analisis Multivariado/Parcial 3/Data/In/"
dir.output     <- "/Users/pedropablo/OneDrive/R/Analisis Multivariado/Parcial 3/Data/Out/"
library(car) # Transformación de poder
library(ggplot2) # Gráficas
library(dplyr) # Manejo de datos, ggplot2 trabaja mejor con dplyr
library(tibble) # Caso especial de un data.frame
library(MVN) # Pruebas de normalidad multivariada
library(ellipse)
#load(paste(dir.principal,"Multivariado.RData",sep=""))
```
## PUNTO 5.4
Use los datos del sudor de la tabla 5.1:

\centerline{\includegraphics[height=4in]{TABLA5.1.PNG}}

Definimos entonces las variables de las siguiente manera:

X1: Sweat Rate (Tasa de Sudor)$\\$
X2: Sodium (Contenido de Sodio)$\\$
X3: Potasssium (Contenido de Potasio)$\\$

* Determine los ejes de la elipsoide del 90% de confidencia para $\mu$. Determine la longitud de los ejes.

Para el caso de $p=3$, los ejes de la región de confianza o Elipse de confianza y sus respectivas longitudes relativas, son determinados a partir de los eigen-valores y eigen-vectores de S.  Para los datos de la tabla 5.1 tenemos $\underline{\overline{X}}$ y $\mathrm{S}$ definida de la siguiente manera:

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
X <- read.table(paste(dir.input,"T5-1.DAT",sep=""))
H0 <- cbind(4,50,10)
alpha <- 0.10
colnames(X) <- c("X1","X2","X3")
xbar1 <- mean(X$X1)
xbar2 <- mean(X$X2)
xbar3 <- mean(X$X3)
n <- dim(X)[1]
p <- dim(X)[2]
xbar <- matrix(rbind(xbar1,xbar2,xbar3),ncol=1)
xbar
S <- cov(X)
S
S1 <- solve(S)
#S1

T2 <- n%*%(t(xbar)-H0)%*%S1%*%(xbar-t(H0))
#T2

FVC <- (n-1)*p/(n-p)*qf(1-alpha, p, n-p, lower.tail = TRUE, log.p = FALSE)
#FVC

e <- eigen(S)
lambda <- e$values
ei <- e$vectors

#if(T2>FVC){
#  print("Rechaza H0")
#} else{
#  print("Acepta H0")
#}  


#library(ellipse)
#     plot(ellipse(S,centre=xbar,t=sqrt(((n-1)*p/(n*(n-p)))*qf(0.90,p,n-p))),type="l")
#     points(xbar[1,],xbar[2,])

#     eigen(S)
```

Para los eigen-valores y eigen-vectores se tiene:

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
e
```

Iniciando en el centro $\underline{\overline{X}}$, los ejes del elipsoide de confianza son:

$\pm\sqrt{\lambda_i}\sqrt{\dfrac{(n-1)p}{(n-p)n}F_{\alpha;p,n-p}}e_i$

con $Se_i=\lambda_ie_i$ para $i=1,2,3$.

Para el calculo de las semi-longitudes tenemos:
$\pm\sqrt{\lambda_i}\sqrt{\dfrac{(n-1)p}{(n-p)n}F_{\alpha;p,n-p}}$ 

Tenemos entonces para los datos que las semi-longitudes son las siguientes:

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
longitudes <- matrix(sqrt(e$values)*sqrt(((n-1)*p)/((n-p)*n)*qf(1-alpha, p, n-p, lower.tail = TRUE, log.p = FALSE)),ncol=1)
longitudes
```

Para el calculo de los ejes, usaremos los eigen-vectores, teniendo como resultado lo siguiente:

$\pm(9.0506741)\begin{bmatrix} -0.05084144\\ 0.99828352\\ 0.02907156\\end{bmatrix}$

$\pm(1.3607857)\begin{bmatrix} -0.57370364\\ 0.05302042\\ 0.81734508\\\end{bmatrix}$

$\pm(0.7292367)\begin{bmatrix} 0.81748351\\ -0.02487655\\ 0.57541452\\\end{bmatrix}$

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
#longitudes[1]*e$vectors[,1]
#longitudes[2]*e$vectors[,2]
#longitudes[3]*e$vectors[,3]
#e$vectors
```

El intervalos $T^2$ con un nivel de confianza del $90\%$ seria el siguiente:

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
cc <- qf(1-alpha, p, n-p, lower.tail = TRUE, log.p = FALSE)
#sqrt(((n-1)*p)/((n-p))*cc)
mu.L=xbar-matrix(sqrt(((n-1)*p)/((n-p))*cc)*sqrt(diag(S/n)),ncol=1)
mu.U=xbar+matrix(sqrt(((n-1)*p)/((n-p))*cc)*sqrt(diag(S/n)),ncol=1)
T <- cbind(mu.L,mu.U)
par(mfrow =c(1,1))
N <- c(n,n,n)
Media <- xbar
Desv_Estandar <- diag(S)
T2_Low <- T[,1]
T2_Up <- T[,2]
Resultado <- data.frame(N, Media, Desv_Estandar,T2_Low,T2_Up)
Resultado
```

* Construya un grafico QQ para las observaciones en tasa de sudor, contenido de sodio y contenido de potasio respectivamente.  Construir las tres posibles graficas de dispersión para las parejas de observaciones. Es la suposición de normal multivariada aceptada en este caso?

Se realiza el grafico QQ para cada una de las variables:

```{r ,  fig.width=8, fig.height=4, fig.align='center', echo=FALSE}
# Diagnóstico gráfico
par(mfrow = c(1, 3))
qqnorm(X$X1,
       main = "qq-plot Tasa de Sudor",
       xlab = "Cuantiles teoricos",
       ylab = "Cuantiles muestrales")
qqline(X$X1, col = "red")

qqnorm(X$X2,
       main = "qq-plot Contenido de Sodio",
       xlab = "Cuantiles teoricos",
       ylab = "Cuantiles muestrales")
qqline(X$X2, col = "red")

qqnorm(X$X3,
       main = "qq-plot Contenido de Potasio",
       xlab = "Cuantiles teoricos",
       ylab = "Cuantiles muestrales")
qqline(X$X3, col = "red")

```

Del gráfico qqplot se observa que X1 y X2 son claramente normales, para X3 observamos que al principio hay un desvío de los quantiles teóricos, sin embargo podemos concluir que son normales pues solo tres observaciones se desvían de los cuantiles teóricos.

```{r ,  fig.width=8, fig.height=4, fig.align='center', echo=FALSE}
# Pruebas formales
X1_shapiro <- shapiro.test(X$X1)
X2_shapiro <- shapiro.test(X$X2)
X3_shapiro <- shapiro.test(X$X3)

p.univariado <- c(X1_shapiro$p.value, X2_shapiro$p.value,
                  X3_shapiro$p.value)

p.univariado <- as.data.frame(p.univariado)

row.names(p.univariado) <- c("Tasa de Sudor", "Contenido de Sodio",
                             "Contenido de Potasio")

colnames(p.univariado) <- "p-valor"
p.univariado
```

Revisando el resultado de las pruebas formales, se obtiene que los datos son normales ya que tenemos un valor de mayor de $0.5$.

Graficos de dispersión:

```{r ,  fig.width=8, fig.height=4, fig.align='center', echo=FALSE}
pairs(X)
```

En los gráficos de dispersión bi-variados se observa que X1-X2 y X1-X3 tienen una clara dispersión elipsoidal lo que nos puede indicar una normalidad bi-variada. Para X2-X3 no es tan claro en la gráfica, pero da la impresión de normalidad, esto lo comprobaremos con los gráficos chi-cuadrado y pruebas de hipótesis de Mardia.

Ahora se realiza el analisis bivariado por las diferentes combinaciones entre las 3 variables:

```{r ,  fig.width=5, fig.height=3, fig.align='center', echo=FALSE}
par(mfrow = c(1,3))
X1X2 <- mardiaTest(X[, c(1, 2)], qqplot = TRUE)
X1X3 <- mardiaTest(X[, c(1, 3)], qqplot = TRUE)
X2X3 <- mardiaTest(X[, c(2, 3)], qqplot = TRUE)
```

Se observa que los datos para X1-X2, X1-X3 y X2-X3 siguen claramente la línea de los cuantiles teóricos de una normal bi-variada.

```{r ,  fig.width=5, fig.height=8, fig.align='center', echo=FALSE}
par(mfrow =c(1,1))

bivariados <- c("X1 - X2",
                "X1 - X3",
                "X2 - X3")

p.value.kurt <- c(X1X2@p.value.kurt,
                  X1X3@p.value.kurt,
                  X2X3@p.value.kurt)

p.value.skew <- c(X1X2@p.value.skew,
                  X1X3@p.value.skew,
                  X2X3@p.value.skew)

p.value.small <- c(X1X2@p.value.small,
                  X1X3@p.value.small,
                  X2X3@p.value.small)

normalidad.bivariada <- data.frame(bivariados, p.value.kurt, p.value.skew, p.value.small)
normalidad.bivariada
```

De la prueba de Mardia, y los valores p de la kurtosis y la asimetría y con un nivel de confianza del 95%, tenemos que ninguno rechaza la hipótesis nula de que los datos provienen de una distribución normal bi-variada.

Dado que tanto las distribuciones marginales como las distribuciones bi-variadas son normales, podemos concluir que los datos distribuyen normal tres-variado.

## PUNTO 5.9

Harry Roberts, un naturalista para el departamento de Alaska Fish and Game, estudio los osos pardos con la meta de manterner una población saludable.  Mediciones en $n=61$ de osos proveen el siguiente resumen de estadisticas:

Variable    |    Peso (Kg)   | Longitud Cuerpo (cm) |    Cuello (cm)    | Cintura (cm) | Longitud Cabeza (cm) | Ancho Cabeza (cm) 
--------------- | ------------- | -------------------- | ----------------- | ------------------- | -------------------- | -----------------
Media ($\bar{x}$) | 95.52 | 164.38 | 55.69 | 93.39 | 17.98 | 31.13
 
Matriz de Varianzas-Covarianzas S:

 | X1 | X2 | X3 | X4 | X5 | X6 
------|------|------|------|------|------|------
X1 | 3266.46 | 1343.97 | 731.54 | 1175.50 | 162.68 | 238.37 
X2 | 1343.97 | 721.91 | 324.25 | 537.35 | 80.17 | 117.73 
X3 | 731.54 | 324.25 | 179.28 | 281.17 | 39.15 | 56.80 
X4 | 1175.50 | 537.35 | 281.17 | 474.98 | 63.73 | 94.85
X5 | 162.68 | 80.17 | 39.15 | 63.73 | 9.95 | 13.88
X6 | 238.37 | 117.73 | 56.80 | 94.85 | 13.88 | 21.26


Se pide:

### a) Obtenga intervalos simultáneos del 95% de confianza para muestras grandes para las seis poblaciones de las medias de los cuerpos de los osos.

El análisis se realiza con base al vector de medias muestrales y a la matríz de varianzas y covarianzas muestrales de las siguientes variables:

* Peso (kg)
* longitud corporal (cm)
* cuello (cm)
* circunferencia (cm)
* longitud de la cabeza (cm)
* ancho de la cabeza (cm). 

La siguiente función será utilizada para obtener los intervalos de confianza con una $\alpha=0.05$:

$\left(\bar{x_i} -  \sqrt{ \dfrac{(n-1)p}{(n-1)} F_{p,n-p}(\alpha) }  \sqrt{\dfrac{S_{ii}}{n}} ,\  \bar{x_i} + \sqrt{ \dfrac{(n-1)p}{(n-1)} F_{p,n-p}(\alpha) }  \sqrt{\dfrac{S_{ii}}{n}}\right) $

Para $i= 1,2, \cdots ,6$
		
Donde:
		
+ $\bar{x_i}$: Media muestral.
+ $\mu$: Media poblacional.
+ ${S_{ii}}$: Componente de la diagonal de la matriz de varianza y covarianza.
+ $n$: Número de osos.
+ $p$: Número de variables.
+ $\alpha = 0.05$.

Nota: Para hallar el intervalo de confianza simultáneo de las variables, ya se tienen todos los datos y procedemos a calcular los límites superiores e inferiores y se obtiene:

Variable | Límite Inferior | Límite Superior
------|------|------
Peso (Kg) | 67.32 | 123.72
Longitud Cuerpo (cm) | 151.12 | 177.64
Cuello (cm) | 49.08 | 62.30
Cintura (cm) | 82.64 | 104.14
Longitud Cabeza (cm) | 16.42 | 19.54
Ancho Cabeza (cm) | 28.86 | 33.40

+ Peso (kg): El valor real de la media, $\mu$, de la variable estará entre 67.32 kg y 123.72 kg con una probabilidad del 95$\%$, siendo 67.32 y 123.72 el intervalo de confianza arrojado después de calcular el límite inferior y superior con base a $\bar{x_i}$ = 95.52 y a la varianza ${S_{11}}$ = $3266.46$.
+ Longitud corporal (cm): El valor real de la media, $\mu$, de la variable estará entre 151.12 cm y 177.64 cm con una probabilidad del 95$\%$, siendo 151.12 y 177.64 el intervalo de confianza arrojado después de calcular el límite inferior y superior con base a $\bar{x_i}$ = $164.38$ y a la varianza ${S_{11}}= 721.91$.
+ Cuello (cm): El valor real de la media, $\mu$, de la variable estará entre 49.08 y 62.30 con una probabilidad del 95$\%$, siendo 49.08 cm y 62.30 cm el intervalo de confianza arrojado después de calcular el límite inferior y superior con base a $\bar{x_i}$ = $55.69$ y a la varianza ${S_{11}}$ = $179.28$.
+ Cuello (cm): El valor real de la media, $\mu$, de la variable estará entre 49.08 y 62.30 con una probabilidad del 95$\%$, siendo 49.08 cm y 62.30 cm el intervalo de confianza arrojado después de calcular el límite inferior y superior con base a $\bar{x_i}$ = $55.69$ y a la varianza ${S_{11}}$ = $179.28$.
+ Cintura (cm): El valor real de la media, $\mu$, de la variable estará entre 82.64 cm y 104.14 cm con una probabilidad del 95$\%$, siendo 82.64 y 104.14 el intervalo de confianza arrojado después de calcular el límite inferior y superior con base a $\bar{x_i}$ = $93.39$ y a la varianza ${S_{11}}$ = $474.98$.
+ Longitud de la cabeza (cm): El valor real de la media, $\mu$, de la variable estará entre 16.42 cm y 19.54 cm con una probabilidad del 95$\%$, siendo 16.42 y 19.54 el intervalo de confianza arrojado después de calcular el límite inferior y superior con base a $\bar{x_i}$ = $17.98$ y a la varianza ${S_{11}}$ = $9.95$.
+ Ancho de la cabeza (cm):} El valor real de la media, $\mu$, de la variable estará entre 28.86 cm y 33.40 cm con una probabilidad del 95$\%$, siendo 28.86 y 33.40 el intervalo de confianza arrojado después de calcular el límite inferior y superior con base a $\bar{x_i}$ = $31.13$ y a la varianza ${S_{11}}$ = $21.26$.

### b) Obtenga una elipse de confianza simultanea del 95% para el peso medio y la cintura media para muestras grandes.

La siguiente ecuación es la fórmula general de una elipse  de confianza simultanea del 95% para el peso medio $\mu_1$ y la cintura media $\mu_2$  tomada de una muestra de $61$ osos.

$n\begin{bmatrix} \bar{x_1}- \mu _1\\\bar{x_4}- \mu _4 \end{bmatrix} ^t \begin{bmatrix}s_{11} & s_{14} \\s_{14} & s_{44} \end{bmatrix}^{-1} \begin{bmatrix} \bar{x_1}- \mu _1\\\bar{x_4}- \mu _4 \end{bmatrix} \leq  \frac{(n-1)p}{(n-p)} F_{p,n-p}( \alpha )$

Sustituyendo los valores tenemos que la  ecuación en (2) es de la forma:

$61\begin{bmatrix} 95.52- \mu _1\\93.39- \mu _4 \end{bmatrix} ^t \begin{bmatrix}3266.46 & 1175.50 \\1175.50 & 474.98 \end{bmatrix}^{-1} \begin{bmatrix} 95.52- \mu _1\\93.39- \mu _4 \end{bmatrix} \leq  \frac{(61-1)6}{(61-6)} F_{6,55}( 0.05 ) = 0.2434$

Donde la matriz de varianza y covarianza para las variables  peso y cintura tomadas de los $61$  datos de los osos pardos está dada por:

$S_2 = \begin{bmatrix}3266.46 & 1175.50 \\1175.50 & 474.98 \end{bmatrix}$ \\

Simplificando la  expresión anterior, está se reduce a la siguiente elipse de confianza:

$(0.002798)(95.52- \mu _1)^2 -2(0.006926)(93.39- \mu _4 )(95.52- \mu _1) +(0.01924)(93.39- \mu _4)^2 \leq 0.2434$

Para la construcción de la elipse se procede a encontrar los valores  y vectores propios de  $S_2$

Así los valores propios  son: 
		
$\lambda_1 = 3695.52$  y $\lambda_2 = 45.92$,  los respectivos vectores propios  asociados a  los valores propios  están dados por: 

$\underline{e_1} = \begin{bmatrix} -0.939 \\-0.343 \end{bmatrix} $\\

y

$\underline{e_2} = \begin{bmatrix}  0.342\\-0.939 \end{bmatrix} $

Las semi-longitudes  del eje mayor y menor son respectivamente

$\sqrt{\lambda_1} \sqrt{ \dfrac{(n-1)p}{(n-1)} F_{p,n-p}(\alpha) } = \sqrt{3695.52} \sqrt{ \dfrac{(61-1)6}{(61-1)} F_{6,55}(0.05) } = 29.99$\\

$\sqrt{\lambda_2} \sqrt{ \dfrac{(n-1)p}{(n-1)} F_{p,n-p}(\alpha) } = \sqrt{ 45.92} \sqrt{ \dfrac{(61-1)6}{(61-1)} F_{6,55}(0.05) } = 3.343 $\\

Los ejes de la elipse de confianza  caen a lo largo de \\\\  
$\underline{e_1} = \begin{bmatrix} -0.939 \\-0.343 \end{bmatrix} $ y  \
$\underline{e_2} = \begin{bmatrix}  0.342\\-0.939 \end{bmatrix} $  \\\\ 
		
cuando estos vectores son graficados desde el origen 

$\underline{\overline{X_2}}= \begin{bmatrix} 95.25 \\93.39  \end{bmatrix}  $.
		
Ahora una indicación de la elongación de la elipse de confianza está dada por el cociente entre la longitud del eje mayor y longitud del eje menor es decir
		
$\dfrac{2\sqrt{3695.52} \sqrt{ \dfrac{(61-1)6}{(61-1)} F_{6,55}(0.05) }}{2\sqrt{ 45.92} \sqrt{ \dfrac{(61-1)6}{(61-1)} F_{6,55}(0.05) }} = \dfrac{\sqrt{3695.52}}{\sqrt{45.92}}= 8.97$\\

Lo que indica que el eje mayor es 8.97 veces el eje menor.

Ahora los ejes del elipsoide  de confianza del 95% son:

$\pm \sqrt{3695.52} \sqrt{ \dfrac{(61-1)6}{(61-1)} F_{6,55}(0.05) }\times   \begin{bmatrix} -0.939 \\-0.343 \end{bmatrix}$  

y 
		
$\pm  \sqrt{45.92} \sqrt{ \dfrac{(61-1)6}{(61-1)} F_{6,55}(0.05) }\times   \begin{bmatrix}  0.342\\-0.939 \end{bmatrix}$ \\ 
		
donde $F_{6,55}(0.05)= 2.268717 $.
		
Utilizando librería <ellipse> de <R> se procedió a calcular la elipse de confianza  del 95%  para las variables peso y cintura de los osos pardos.

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
x=c(95.52, 164.38, 55.69, 93.39, 17.98, 31.13  )
s=c(3266.46, 721.91, 179.28, 474.98, 9.95, 21.26)
f=qf(0.05, 6, 55, lower.tail=F)
inferior = x-sqrt(((61-1)*6*f)/(61-6) )*sqrt(s/61)
inferior
superior= x+sqrt(((61-1)*6*f)/(61-6) )*sqrt(s/61)
superior
d=data.frame(inferior,superior)
d

x1 <- c(3266.46, 1175.50 )
x4 <- c(1175.50, 474.98 )
S <- rbind(x1,x4)
S
dbar=c(95.52, 93.39)
dbar
v <- eigen(S)
v

library(ellipse)
plot(ellipse(S, centre = c(95.52, 93.39), t = sqrt(((61-1)*6/(61*(61-6)))*qf(0.95,6,61-6))), type="l", xlim = c(60,130), ylim = c(70, 120),lwd = 1, col = 2,
     main="Región de confianza del 95% para tamaño de muestra grande", xlab = "Peso",
     ylab = "Cintura")
```

Notemos que  la matriz de varianza y covarianza para las variables peso y cintura de los osos pardos tiene una correlación  de $1175.68$. Además la figura representa una elipse de confianza simultánea del 95%  para las variables peso (kg) y cintura (cm) media de  una muestra de $61$ osos pardos.

### c) Obtenga un intervalo de confianza Bonferroni del  95% para las  seis medias de la parte (a)

En este punto se hallarán los intervalos de confianza simultáneos de Bonferroni de 95% para los valores de de las $x_i$, los valores de los límites inferlos y superiores de cada variable, deben ser mayores y menores, respectivamente, en Bonferroni respecto a los hallados en punto a).

La ecuación para calcular los intervalos de confianza de Bonferroni es:

$\left(\bar{x_i} -  t_{\frac{ \alpha }{2p},\  n-1}  \sqrt{\dfrac{S_{ii}}{n}} ;\  \bar{x_i} + t_{\frac{ \alpha }{2p};\  n-1}  \sqrt{\dfrac{S_{ii}}{n}}\right) $

Para $ i= 1,2, \cdots ,6$

A continuación se observa que los intervalos de confianza de Bonferroni hallados, efectivamente se encuentran entre los valores de los intervalos de confianza del punto a):

Variable | Límite Inferior | Límite Superior
------|------|------
Peso (Kg) | 75.55 | 115.49
Longitud Cuerpo (cm) | 154.99 | 173.77
Cuello (cm) | 51.01 | 60.37
Cintura (cm) | 85.78 | 101.00
Longitud Cabeza (cm) | 16.88 | 19.08
Ancho Cabeza (cm) | 29.52 | 32.74

### d) Consulte la parte (b) construya un rectángulo de confianza del  95\% para el peso medio y la cintura media  usando m = 6, compare esté  de confianza con la elipse de confianza en la parte (b)

Para construir un rectángulo de Bonferroni  del  95%  simultaneo para las variables peso y cintura de los osos pardos y compararlo con la elipse de confianza simultánea del 95% de la parte (b) se utiliza un código en el programa estadístico R.

Para este código se utilizan los intervalos de confianzas de Bonferroni del inciso (c) tomando $ t_{\frac{ \alpha }{2m}} $ con $m=6$

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
x=c(95.52, 164.38, 55.69, 93.39, 17.98, 31.13  )
s=c(3266.46, 721.91, 179.28, 474.98, 9.95, 21.26)
f=qf(0.05, 6, 55, lower.tail=F)
inferior = x-sqrt(((61-1)*6*f)/(61-6) )*sqrt(s/61)
inferior
superior= x+sqrt(((61-1)*6*f)/(61-6) )*sqrt(s/61)
superior
d=data.frame(inferior,superior)
d

x1 <- c(3266.46, 1175.50 )
x4 <- c(1175.50, 474.98 )
S <- rbind(x1,x4)
S
dbar=c(95.52, 93.39)
dbar
v <- eigen(S)
v

library(ellipse)
plot(ellipse(S, centre = c(95.52, 93.39), t = sqrt(((61-1)*6/(61*(61-6)))*qf(0.95,6,61-6))), type="l", xlim = c(60,130), ylim = c(70, 120),lwd = 1, col = 2,
     main="Región de confianza del 95% para tamaño de muestra grande", xlab = "Peso",
     ylab = "Cintura")
lines(x=c(115.49,115.49), y=c(85.78,101), lty = 2, lwd = 1)
lines(x=c(75.55,75.55), y=c(85.78,101), lty = 2, lwd = 1)
lines(x=c(75.55,115.49), y=c(101,101), lty = 2, lwd = 1)
lines(x=c(75.55,115.49), y=c(85.78,85.78), lty = 2, lwd = 1)
lines(x=c(123.72,123.72), y=c(82.64,104.14), lty = 2, lwd = 1, col = 8)
lines(x=c(67.32,67.32), y=c(82.64,104.14), lty = 2, lwd = 1, col = 8)
lines(x=c(67.32,123.72), y=c(104.14,104.14), lty = 2, lwd = 1, col = 8)
lines(x=c(67.32,123.72), y=c(82.64,82.64), lty = 2, lwd = 1, col = 8)
```

Como ya habíamos mencionado la matriz de varianza y covarianza para las variables peso y cintura de los osos pardos tiene una correlación muy grande de $1175.68$, está correlación es positiva, por eso observamos que la inclinación de la gráfica para elipse de confianza esta inclinada hacia la derecha.
		
Notemos que los  intervalos de confianza individuales de Bonferroni calculados  para cada una de las seis variables en la parte (c) están contenidos en los intervalos de confianza individuales calculados en la parte (b) para cada una de las seis variables es decir el intervalo de confianza para  la variable peso  para un intervalo de Bonferroni es $(75.55, \ 115.49)$  y está  contenido en el intervalo $(67.32, \ 123.72)$ por lo cual  los de Bonferroni individuales tienen menor confianza, pero más precisos de igual forma el resto de intervalo para cada variables. 

### e) Obtenga  un intervalos de confianza  del  95%  de Bonferroni para Ancho medio de la cabeza - longitud media de la cabeza. El uso 	$m= 6+1=7$ permite esta afirmación, así como la declaración sobre cada media individual.

Para hallar el intervalo de confianza  Bonferroni  simultaneo del 95%  para  la diferencia entre el ancho medio de la cabeza  $ (\mu _5) $ y la longitud media de la cabeza $(\mu_6) $,  la diferencia de medias $\mu_6-\mu _5 $ está dentro del siguiente intervalo  con $m=7$ 

$\left(\bar{x_6}- \bar{x_5} -  t_{\frac{ \alpha }{2m},\  n-1}  \sqrt{\dfrac{S_{66}-2S_{65}+ S_{55}}{61}} ;\  \bar{x_6}-\bar{x_5} +  t_{\frac{ \alpha }{2m},\  n-1}  \sqrt{\dfrac{S_{66}-2S_{65}+ S_{55}}{61}}\right)$

Sustituyendo los valores en la fórmula de arriba tenemos:

$31.13- 17.98 \pm  t_{\frac{ 0.05 }{14} }(60) \times  \sqrt{\dfrac{21.26-2(13.88)+ 9.95}{61}}$

Utilizando en programa R se calcula  $t_{\frac{ 0.05 }{14}  }(60)=  t_{0.0036  }(60) =  2.783$

Haciendo  las operaciones pertinentes se llega a que 
		
$$12.49\leq  \mu_6-\mu _5   \leq  13.81$$

De donde se puede concluir que el intervalo de confianza simultaneo  de Bonferroni del 95%  para las dos variables  de la diferencia media entre el ancho de la cabeza y la longitud de la cabeza  se encuentra entre $15.49cm$ y $13.81cm$

## PUNTO 5.21

Usando los datos del contenido mineral de los huesos de la Tabla 1.8, construya el intervalo de Bonferroni al $95\%$ para las medias individuales.  Tambien encuentre el $T^2$-Intervalo simultaneo, compare los dos intervalos hallados.

\centerline{\includegraphics[height=4in]{TABLA1.8.PNG}}

Definimos entonces las variables de las siguiente manera:

X1: Dominant Radius$\\$
X2: Radius$\\$
X3: Dominant Humerus$\\$
X4: Humerus$\\$
X5: Dominant ulna$\\$
X6: Ulna$\\$

Para hallar los intervalos de Bonferroni y los $T^2$ se calcula $\underline{\overline{X}}$ y $\mathrm{S}$, para Bonferroni los intervalos estan dados por:

$\bar{x_i} \pm  t_{\frac{ \alpha }{2p},\  n-1}  \sqrt{\dfrac{S_{ii}}{n}}$

Así que para los datos del ejercicio los intervalos de Bonferroni con un nivel de confianza del $95\%$ serian:

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
X <- read.table(paste(dir.input,"T1-8.DAT",sep=""),col.names = c("X1", "X2", "X3", "X4", "X5", "X6"))
alpha <- 0.05
xbar1 <- mean(X$X1)
xbar2 <- mean(X$X2)
xbar3 <- mean(X$X3)
xbar4 <- mean(X$X4)
xbar5 <- mean(X$X5)
xbar6 <- mean(X$X6)

n <- dim(X)[1]
p <- dim(X)[2]
xbar <- matrix(rbind(xbar1,xbar2,xbar3,xbar4,xbar5,xbar6),ncol=1)
colnames(xbar) <- ("Media estimada")
row.names(xbar) <- c("X1", "X2", "X3", "X4", "X5", "X6")
print("Vector de Medias")
xbar

S <- cov(X)
print("Matriz de Varianzas-Covarianzas")
S
S1 <- solve(S)
print("Elementos de la diagonal de la inversa de la Matriz de Varianzas-Covarianzas")
diag(S)

cc <- qt(alpha/(2*p),n-1,lower.tail=F)
print("Estadístico de prueba de la distribución T")
cc
mu.L=xbar-cc*matrix(sqrt(diag(S/n)),ncol=1)
mu.U=xbar+cc*matrix(sqrt(diag(S/n)),ncol=1)
B <- cbind(mu.L,mu.U)
print("Intervalos T^2 al 95% de confianza")
B
```

A continuación se calculan los mismos intervalos pero con el método de Bonferroni fijando el $\alpha$ al 95%.

```{r ,  fig.width=5, fig.height=5, fig.align='center', echo=FALSE}
cc <- qf(1-alpha, p, n-p, lower.tail = TRUE, log.p = FALSE)
sqrt(((n-1)*p)/((n-p))*cc)
mu.L=xbar-matrix(sqrt(((n-1)*p)/((n-p))*cc)*sqrt(diag(S/n)),ncol=1)
mu.U=xbar+matrix(sqrt(((n-1)*p)/((n-p))*cc)*sqrt(diag(S/n)),ncol=1)
T <- cbind(mu.L,mu.U)

print("Intervalos de Bonferroni al 95% de confianza")

T
```



```{r ,  fig.width=5, fig.height=8, fig.align='center', echo=FALSE}
par(mfrow =c(1,1))

#Variables <- c("X1",
#                "X2",
#                "X3",
#                "X4",
#                "X5",
#                "X6")

N <- c(n,n,n,n,n,n)

Media <- xbar

Desv_Estandar <- diag(S)

T2_Low <- T[,1]

T2_Up <- T[,2]

Longitud_T2 <- T[,2]-T[,1]

B_Low <- B[,1]

B_Up <- B[,2]                  

Longitud_B <- B[,2]-B[,1]               

Resultado <- data.frame(N, Media, Desv_Estandar,T2_Low,T2_Up,Longitud_T2,B_Low,B_Up,Longitud_B)

print("Resultados consolidados")
Resultado <- as.data.frame(Resultado)
rownames(Resultado) <- c("X1", "X2", "X3", "X4", "X5", "X6")

```

Se concluye que con un nivel de confianza las medias de las poblaciones se encuentren en los intervalos calculados, siendo los de Bonferroni más angostos (precisos).

Se observa que los intervalos de Bonferroni siempre son más precisos que los intervalos producidos por el método $T^{2}$, siendo los de $Bonferroni$ más angostos lo que es una característica mejor.